Scholarship: academic study or achievement; learning of a high level.
- the character, qualities, activity, or attainments of a scholar : LEARNING

Open Scholarship advocates for research to be transparent and openly available to all. In this workshop, we’ll give an overview of the Open Science movement and the general principles including access to publications and the underlying research process, FAIR data, and initiatives within scholarly communications that support “openness” of the research endeavor (preprints, registered reports, persistent identifiers, and community engagement platforms).
Recorded Thursday, October 28, 2021


[Jim Morris-Knower]I think Sarah and Gayle and I have some things to share about open science and open scholarship. And so we came up with an agenda because that seemed  like a good thing to do. Basically what we'd like to do is sort of set the parameters of what we mean by open scholarship and open science and what that means, and then talk a little bit about why. It's like the what and then the why. Each one of us will take a particular area of open scholarship and go into it. So Sarah will be discussing in detail open data and Gail will be talking about open access publications and I'll talk about research impact. 

And these are sort of three parts of the open scholarship umbrella, but it's not everything. And it's like we  couldn't talk about everything, we had to pick. So I think it's helpful to start by talking about the definitions. 
I love this umbrella image because really when we talk about open scholarship and open science, it's really many things under the umbrella. And so like I said, we'll be talking about three things under that umbrella. But depending on your discipline, your subject area, your field, the components may be different in terms of your research life cycle and your workflow and things like that. 

So, just to distinguish the difference between open science and open scholarship, because they're often used interchangeably, this is the definition of open science we're working with from an EU-funded group called FOSTER.

Open Science: "A movement to make scientific research, data and dissemination *accessible* to all levels of an inquiring society." 

Open scholarship is just a bigger umbrella  and it includes all areas. 
So if you're in the humanities, for example, the notion of open science it is not something that you typically are concerned with, but certainly there are elements of open scholarship more broadly considered-- opening up the research lifecycle and the practices of being a scholar -- that would be included in what you talk about. 
So this umbrella talks about everything from open data to open notebooks, things that we won't have time to talk about like open peer review, which I think it's an absolutely fascinating topic, somewhat controversial and as you can imagine, if you're someone who's involved in peer review, that the notion of opening that up is somewhat challenging in some way. 
So, open scholarship just includes everything we're talking about, open science, but just more broadly in terms of opening up the scholarly and research environment. 

And then to move on to talk about "Why open science?" and again, we're going to probably be using this interchangeably. When we say open science, I think I speak for all, what we really mean is open scholarship. 

So if you're not in the sciences, when we say open science, we're speaking to you, but the terms are often used interchangeably. 
And we could spend the entire hour and a half talking about "Why open science?" because it's fascinating. Sarah and I were just talking about how this is the future. I mean, it really is. It's every time I check my email inbox, there's something new about challenges of open scholarship and open science. If you're an early-career researcher or a late-career researcher, you're going to be talking about this for your entire career. So what are we really talking about why open science, two fundamental foundational aspects. 

------------

"The underlying assertion of science is that the world is understandable: fueled by human curiosity and need, this has led us on a journey that has pulled away the veil of mystery surrounding the cosmos and in turn has shaped our very existence. 
The underlying assertion of computing is that the world is computable: this also has led us on a journey that has irreversibly changed humanity. It was once the case that developing software-intensive systems was the domain of a relative few, but as computing has woven its way into the interstitial spaces of civilization, development is no longer just the domain of professionally trained computer scientists and engineers, for now there has grown a much larger community of amateur and incidental developers, people who must build computational systems as part of their primary focus. 
In this presentation, we will examine the nature of this shift and consider the consequences not only for our profession but for the world that increasingly relies on such systems. We will pay particular attention to the importance of computational thinking for the masses, and how we as professionals have a responsibility to shape the conversation." 

-----------

- One is research equity which is, it's really about opening up the access to scholarship or science in some way. And I think again, without going too deeply into it, if nothing else, the notion of, especially if you're a scholar who publishes and you're at Cornell, the model is typically to publish your research in a peer reviewed journal and then that gets sold back to your institution [laughs] by a publisher. And it's a model that, now that we're in the era of the internet, it's kind of a little odd, but it's the way it is. So there's this notion of equity and I think we'll keep coming back to this. 

- And directly connected to that is the quality of research, that actually not only is it quote unquote, the right thing to do. That to make the research outputs in as many hands as possible because it's the right thing to do, but it also makes for better scholarship and better science, because that's the way science works, is it's based on transparency. 
I was thinking of this as an analogy that science should be, it is supposed to be open. You're not supposed to be hiding anything, but a lot of the traditional paywalls do that. I was thinking like what you're not going to see anytime soon is open magic. You know [laughs], people are like, I'm going to explain the trick and then I'm going to show it to you. That's like, that doesn't work, but open science is actually, that's where we are, is the notion of it makes for a better, the quality of research is better because it's transparent and open and as many different parts of that research lifecycle as possible. Okay, and now I'm going to turn it over to Gail to talk about the research process. 

[Gail Steinhart] Right, you can think of research as a process that begins with coming up with an idea and a plan to do some research to execute that plan, whether you are doing lab experiments or field work or interviews or compiling some texts to analyze. That work then results in some data that you have to manage and arrange and clean up in order to analyze it and produce something that you can disseminate to the public, to your colleagues. And there are opportunities at every phase of that process to practice openness. And we thought we would start by inquiring with you what kinds of open scholarship practices you already engage in. You don't have to necessarily respond with one of those phases of the research lifecycle, but say you share your lab notebook openly, or you publish open access, or anything you do to share your research process or results at any stage we'd love to hear from you. And Sarah, I don't know if you need to give people any more information on how to participate in the poll. 

[Sarah J. Wright] Yeah, see you can either go to this poll: "ev.com/sarahwright405" url, or you can text. So you would put "37607" into your who you're sending it to and then text "Sarahwright405" to that number. And then once you've done that, that will help get you into this Poll Everywhere session, and then you can text what open scholarship practices you engage in now and it should show up on the screen.

[Gail] So we'll do a little waiting here. 
[Sarah] That was me testing. Yay, Somebody else. [Gail] Sarah, there's a request to paste the poll link in the chat. [Sarah] Oh, that it's a brilliant idea. 
[Gail] So give that, that maybe another half a minute. But I'm glad to see and maybe not surprised to see that people are already doing some open practices.  Sarah, maybe you can also put the link to the slides. in the chat. Open access paper, data sharing, code sharing, great. So we have some data sharers, some paper sharers, more data and code sharers. That's great. All right, let's move on. And I wanted Sarah  to show the slides because we wanted to highlight just how much support there is at Cornell for each phase of the research process, there are a lot of tools and practices and services listed here. Each one hyperlink to either a service unit at Cornell, a service point, a website, a library guide, something. So lots of, lots of support throughout the research process. If you go to the next slide, I've indicated which ones I think are most obviously opportunities to practice open scholarship in some way. Next slide. And as Jim said, we can't talk about all of these. So we're kinda focused on dissemination phase of, of open scholarship and we will talk about open access publishing and other ways to share writing, share your data and research impact. And at this point I think Sarah takes over with data. 

[Sarah] I had to get  that unmute button to pop up before I can talk. So yeah, I want to start just by defining what we mean when we're talking about open data. We're trying to make sure we include definitions that kind of set the stage at every point here. So the open date, the hand. Says that data, open data is data that can be freely used, reused, or redistributed by any one subject only at most to the requirement to attribute and ShareAlike. So the goal of open scholarship is really to ensure free availability and usability of scholarly publications. Data. The methodologies including code and algorithms, et cetera, et cetera. And one of the goals of Open Knowledge, as Jim started out with, is really just to close the knowledge gaps and open the level, the playing field for researchers globally. And to make it easier for us to build on others research, which is the point of scholarship, right? So for example, many researchers and Africa don't have access to the same subscription databases that we do. So they really face more challenges when trying to do research. So this is trying to combat that. And I also want to backup a little bit. And to advance my slide. There we go. And talk about what is it that I mean, when I talk about data too? So data is not just the tables and figures, It's not just your Excel files. That's a lot more than that. It's any of the content that you collect, create are used to answer a research question. So for exam, for example, pictures on your phone. They're not necessarily data. They're just pictures on your phone. Until you use those images to answer a research question, then they can become the data in support of your research. So really, data can be anything used to answer a research question. And I want to emphasize that if at any point you have questions, please interrupt, raise your hand, put something in chat, and hopefully my co presenters will interrupt me if I don't see it put in chat. But I encourage open discussion here, open data, open discussion. So, but let's deconstruct these elements just a little bit more. What do we mean when we say open data should be freely used, freely used, freely reused, and redistributed by anyone. So first availability and access. So when I was in grad school, shared via permission by author was really the norm. And why, why is this a problem? Well, it creates a barrier that you have to get across before you can access the data. And the researcher might be too busy to answer your emails or might think that you're not worthy of being with her data, right? So it's another barrier. Another problem that I saw a lot of the time is, have you ever tried to get data and then been given a PDF that's not very accessible that way, right? So the goal here is to make the data available as a whole. And in a convenient and modifiable forums. So something that's accessible and available to you. So reuse and redistribution. You should best practices really to avoid lice and says including no derivatives designation, avoid attribution stacking. So like we, we recommend very strongly CC 0 or at the most CC-BY for your data. And in fact, CC Zero is required by some repositories like the Dryad data repository. Because one of the problems here is what happens when somebody wants to do a meta-analysis using the data and there's a no derivatives designation on there. You really can't reuse the data. Universal participation. What do we mean by that? Truly open data allows anyone to use the data. However, I have gotten feedback from researchers. They get really kind of concerned at this point. And I want to stress that your documentation should make clear the granularity and context of the data. So if it's wrong for reuse in certain other situations, if the, if it's recorded only to the third decimal point and you really need something more granular to, to use it in a more in-depth situation, for example. So you provide enough information along with their data to enable future users to decide whether it is appropriate to use in their studies. So a little bit of a, I guess, a less altruistic reason for making your data more open. Open data is also very connected with reproducibility. And we, I think we all know that it's been a really hot topic for several years now. And this is, these are the results of a survey conducted by nature relating to whether there is or isn't a reproducibility crisis in science. So, have you failed to reproduce an experiment? Have any of you actually failed to produce an experiment? Can throw a thumbs up green check mark in your responses if you have. And if you have, you are definitely not alone. Either someone else's or their own data. Many researchers have failed to reproduce experiments. And one thing we can do to improve our ability to reproduce findings is just making openly, openly available the underlying data, as well as having increased transparency throughout the whole research process. So this can help others reproduce your results, and it can also help you reproduce your results. I've been there, I was a grad student and I thought I would remember all the details of everything I did. And yet two weeks later I did two years later when I was writing my thesis and try to put that together, not so much. So it becomes clear really quickly when you're living it, how important that documentation is to yourself as well as others. So it's not just for others, it's for you to. Another way to think about making your data more openness, to think about the fair principles, findable, accessible, interoperable, and reusable. The fair guiding principles for research data were developed by representatives from academia, industry, funding agencies and scholarly publishers from all over the world. And the goal here is really to make, make your data fair, findable, accessible, interoperable, reusable by both humans and machines. And we're aiming to increase fairness. We're probably not achieving it. So this, like a lot of things that we're talking about today, is something that you might move yourself towards incrementally. It's a goal. It's not something that we're achieving yet, but we're, we're trying. And what we'll talk about today is really achievable things that you can do to increase your data's fairness and openness. And I just do want to point out that recommendations, recommending or requiring that your data meet fair principles is increasing across research communities. Publishers and funders are asking you to do it. And these guidelines are also an important measure for research data repositories. So when you're looking at and trying to choose a research data repository for your data. This is one measure that you can compare and contrast them, evaluate them B-A. So over these next few slides, I'm going to talk about things that we can do to our data to make it more fair. So two of the ways to make information where findable, accessible and usable is to take advantage of processed, persistent, stable identifiers. So the DOI is a recognized standard for creating persistent links. And I'm sure most, if not all of you have followed a DOI directly to a research article. But the same is also being done for research data and is expanding to other places as well. They're talking about DOIs for instrumentation and things like that. For your code, all those things. Another type of persistent identifier is the orchid, and hopefully most of you already have an orchid. Can I see some thumbs up? What can you guys do in your responses? You give me a check mark or a thumbs up, forgetting what the responses available to you guys are. Oops, let's unclick it off. I think no responses in a webinar. I think people can just put a plus one in chat if you haven't or good or okay. Or a hands up, I think you can raise your hands. There's a plus one from Jim. There's some are less, one's. Yea. So for those who don't know which I think are probably not too many of you guys here because we've done a pretty good job of getting the word out at Cornell. But an orchid is just a personal identifier that distinguishes you from every other identifier. So I'm a great example. My name is Sarah, Right? I work in the library. There's another Sarah, right? That works in the library. There's another Sarah right? That does research in the College of Veterinary Medicine here at Cornell. And there are lots of other Zara rights at other institutions that also do some pretty interesting research I know because I've found them by accident when looking for myself. So I, it's really important that I use an orchid to disambiguate myself from other researchers and keep my my Google, you know, the the publications listed in Google straight. Like just my publications, not the other Sarah right at the College of Veterinary Medicine mixed in, which has happened before. So having a or it could just make sure that you can integrate yourself unambiguously in, into your research work, workflows such as manuscript submissions, grant applications, etc. Just to make sure your work is always linked back to you. And the link is here in case you would like to visit the guide that tells you more about signing up for an orchid. So interoperable data. This is the, the, I is kind of my, one of my favorite letters in the, of the fair principles. But one of the ways to ensure that data is more interoperable is to save an open, stable formats rather than proprietary formats. So well, it's fine to provide a copy of your files in a proprietary or analysis ready format. And I know that sometimes a proprietary, proprietary format unavoidable. It's the only thing you can look at the data in. But when possible, you should always save a copy and a format that makes it more portable across platforms and make it more likely that it can be preserved into the future. That's my alarm letting me know what time it is. Sorry. This painful shows some of the formats that make make it more likely that can be preserved into the future. And I added a link down at the bottom to even more information. So you have a four, if you have a format that's not listed in this table, there's more information on that E comments pages. So for example, while you might use excel for analysis or to collect your data or something like that. You would also want to save your data as a CSV comma separated value file, which can be opened and read into a number of different analysis programs. And in cases where important functionality is lost by converting into an accessible, interoperable preservation friendly format. We always, we also recommend to deposit and share both versions of the data. So it's not like you have to choose an either or. You can put in both versions just to make it both accessible and interoperable and likely to be preserved. And if you're really interested in learning more about tabular data, I can talk way too much about this and get into way to, way more stuff. But we actually did a workshop a week, a week or two ago on tidy reusable data that is recorded and available and feel and we'll put it on the RD MSG research data management service group website, which I have a link to out another slide. So we'll be sharing that recording there soon and you can find it there or contact me if you want it sooner than that. We're also happy to have these conversations at anytime. We love talking this stuff. Okay, finally, the, the are the reusable data. So how do we make sure that your data's reusable? We talked about for formats for reusability. But the goal here is to also provide documentation of your methods and data count contents. So including your code values, your variable labels, all the information that someone else needs to be able to understand your work. You should also try to treat data as a standalone publication that doesn't rely on other published articles to give it context. So a lot of the time when we get data submissions, people say that link to the paper that is contains all the methods information. And we try to push back on that a little bit because not everybody has access to those. If it's open access, we push back less because you should be able to get to the article. If it's not open access than lots of people can't get to that article because it's subscription-based and not everybody is as lucky as we heart. He are here at Cornell. Huge access that we have. You should also think about in that documentation. You want to make sure it's as broad as possible because somebody else might have an entirely new use for your data that you're not thinking about. So it's important to have that full documentation. And we do help people with making sure that it's understandable by others, not in the field and things like that. Okay. So making your data fair, sorry, I have a fruit fly in my office. Making your data fair and open may seem a little overwhelming, or you might just have questions that I haven't addressed during this session. There's so much to talk about here. But there is a group here on campus that's happy to have these conversations. We get really excited about talking about this. So we are the research data management service group, the RD MSG for short. And I've got the website link here, as well as our e-mail address. We we serve all disciplines and will help you at any stage of the data lifecycle. We can help you early on with project planning. Thinking about electronic lab notebooks. Using things to make the whole process more transparent, like open science Framework, preregistration or projects. Or we can help you later on in the life cycle with curating data sets for archiving and sharing. And you can visit our website for more information or email us to arrange consultation or just ask a question. Speaking of archiving and sharing. So E comments is Cornell's to digital repository. And really one of the easiest ways to ensure that your data are fear is to deposit it with a reputable, reputable archive or repository. So there are lots of different repositories out there and we will also help you find a different one. If you have a poet, your publisher, your journal publisher is recommending that you put it in a certain place. Or your funders recommend that you put it in a certain place and their disciplinary repositories, et cetera, et cetera. So will also help you find other repositories. We will also help you deposit into a comment which satisfies many of the fair principles. Content deposited into II Commons is free and open. We provide, as I've said about three times, I think we provide data curation services to help you optimize your fairness. So we look at all of those findable, accessible, interoperable, and reusable. And we try to incrementally nudge ourselves down more towards fairness. We are also members of the Data Curation Network, which is a consortium of curators that enables us to match data with curators, with subject expertise. So that's pretty exciting too. And I just wanted to give you an example of something that we've worked with the researcher to make their data more fair. So what we do when we get data deposit is we open up the files, we look at them, we make sure we can open amendment beginning. So for example, you can see the data here is provided as a CSV. So the original file was an Excel file with multiple tabs. It wasn't Square, had figures inserted on the page. There were things about it that were not optimal that we talk about a lot about in that tidy data workshop that I mentioned earlier. So we made recommendations and the researcher updated that and made it much more reusable and better preservation formats. They also added a README file that clearly explains the documentation around the file. We also look at, so this is an easy example, but some submissions we look at whether it's clear what's software is needed to open the file or the font or the, or the versions used to create the data included in the Readme documentation or any file conversions necessary, which already talked about. And then we also do really the basic metadata to. So we have here authors, the abstract information, sponsorship information. We have subject terms here. So this is all to help make it more findable. And then I think I have the bottom half of the page here too. So you can see there's a permanent link for a commons. The default is to assign a handle. We can also do he create a DOI for you. And that would show up in the same place. It will show up here under the handle. We also try to include links to related publications or if you have code that's in GitHub or somewhere else in another repository. We can link to the code just to make sure all of those related things are linked. That's all part of that findable keeping it fair, right? And I skipped there's licensing information which helps people know how they can reuse your data. So this is CC BY so they just won't enter attribution. Okay? And so I just showed you a nice finalized dataset. But open data is not necessarily a destination, it's more of a continuum. So again, we're trying to nudge ourselves along the continuum and just try to get more, more better, trying to get better. So I don't expect any of you to be immediately exemplary practitioners of open data. I am not yet an exemplary practitioner. I am trying every day to be better. But instead, I just want you to think about what small steps you can take towards making your data more open and moving towards more open scholarship. So I've listed here some examples, such as using an orchid, making sure your datasets are shared in a reputable Repository. Have DOIs, adding, reuse and licensing information to your data. But there's a lot of other ways out there that, that folks are increasingly experimenting. Like open research notebooks and pre-registration, like I mentioned earlier. So you may already be doing a lot to make your data and research process transparent and open that I haven't necessarily laid out here. And that is still qualifies and his crate. So before we move on to the next section, I'm almost done with data. I just have a couple of questions for you. So I would love for you to text your response to this question, but also please speak up, throw it in chat. Tell us what you're already doing to make your data open. So since you have already joined this session, yeah, I can see one person at least responded. So you can just text a, B, C, or D. It should show up here instantly. So I'll give folks a minute to respond to this. And I think we might have a couple of new attendees. So if you didn't get the instructions the first time around, you can either go to pull f.com slash Sarah right, for 05 and respond via the web or you can text it to you can take Sarah, right, 4052376 or seven. Thanks Jim for throwing that in there again. So that's awesome. We have a lot of we have a nice even split here between beginning, developing an accomplished. And I'd love to hear examples of what you're doing. But for now, we're going to go ahead to the next slide and ask again, what kind of Open Data practitioner would you like to be? So is it the same? What do you want to stay in the same place you're at? Or do you want to nudge yourself further along now that I've kind of tried to push you in that direction. And I hope that this section has given you some ideas and some information about how to make your data more open, but also who to contact for help. So if you have any kinds of questions about open data, you can just email RD, MSG help and we will be happy to have conversations with you. And if we can't answer the question, we will happily forward your question. I want somebody else. We were happy to discuss pros and cons. We are realists about this too. We know it's sometimes challenging. So that's great. And if you have any questions at this point, I'd love to pause and let you ask any questions. You can put them in the chat, you can raise your hand. I will allow you to talk. Oh wow. I love that the majority of people want to be exemplary. I want to be exemplary. So I don't see any questions coming in. So at this point, I'm just going to hand it over to Gail for Open Access Publishing. Thank you, Sarah. We're going to talk now about ways in which you can make your writing openly accessible to the worlds. So in this segment we'll talk about what open access is. We'll talk a little bit about copyright and managing your rights as an author and then bring those things together. In a discussion of publishing models, including open access, talk about a few alternative ways to share your work and tie it up with best practices. And I hope that sounds good to people. I kept the next slide. So open access literature is digital online, free of charge and free of most copyright and licensing restrictions. And it's really the internet that made open access possible. All of a sudden that it's possible to make things freely available to anyone with an Internet connection to copy them infinitely. And that's, that's really about when it came about. This is a pretty radical and transformative idea. I have to talk to you a little bit about copyright to explain that next slide. So copyright, the purpose of copyright law is to protect the rights of authors, to control what happens to their work as well. And then balance that with the right of the public to have access to information and, and make good use of it. You can think of it as a form of property and it's transferable from one entity to another. And copyright is actually a set of rights that includes, perhaps unsurprisingly, the right to make copies or reproduce content. The way to distribute those copies. The right to create derivative. So for example, the transom translate something into another language or format. The right to display or performer work next slide. So in the scholarly realm, the way those rights might play out include, for example, say you're a graduate student, you've written a paper. And your program allows you to include a paper as a chapter in your dissertation. That would be your right under copyright law as the author of that work. But more generally, academics might want to reuse. Work within and other work say turning manuscript published in one place into a book chapter someplace else. You might want to make or distribute copies of your work for teaching and research purposes. And you might want to grant permission to other people to do the same, and you might want to post their work online. Next, slide. Problems arise though under traditional publishing arrangements when publishers typically demand the complete transfer of copyright from the author to the publisher. So next slide. So what are you to do as an author? Understand what your rights are for sure. If you can find a copy of the publishing agreement on the publisher's website or their copyright policy. That will be really helpful if you have difficulty locating that information. There's a database called Sherpa Romeo that provides that information for journals and publishers that are pretty easy to understand and standardized format. And if you don't like what you see, you can negotiate. And there's useful information. I'm doing that on the copyright Information Center's website. They have a page on copyright management for authors. And there's similar and perhaps more detailed information on the library guide on author writes, he did in collaboration with the Library Copyright folks. Next slide. So what does all this have to do with open access publishing and publishing models? I'm going to preface this part by saying Really I'm talking about journal publishing and, and how journal publishing works here. And we will talk about four kinds of different publishing models that we see commonly and arrange them on the slide from sort of most closed and proprietary on the left, two most open on the right. So starting on the closed and subscription publishers, they earn their revenue obviously by charging subscriptions and limiting access to subscribers, preventing the papers that they provide in their journals. They prevent those from being distributed by other means, by requiring authors to handover copyright. Another end of the spectrum, fully open access journals provide access to everyone and everything's free to read to anyone with an Internet connection. And because they're not trying to limit access, there's no reason for them to require the transfer. Copyright. Somewhere in the middle are a couple of sort of compromise arrangements. I'm publishers allow authors to do something called self our private. Where a subscription journal might allow an author to post some earlier version of their paper on their website on a pre-print service, on a repository like he comments. But not the, typically not the publishers copy and they might require some delay before those earlier drafts become available to read. Under hybrid publishing arrangement, a traditional subscription-based journal might allow an author to, for a fee, make that one article open access. And when you're presented with that opportunity, could seem like a desirable thing to do to promote openness. We say libraries or maybe not a big fan of this model because if you think about it, the journals still charging the institution of a subscription fee. And now the curl is charging authors at that same institution a fee to publish. So they're charging us on both ends. It's a terrific business model. If you're a publisher. It's not so great for Cornell to be charged both for eating and for publishing. So we really discourage people from this type of publishing. It's better if you can seek out a fully open access arrangement or perhaps a self archives archiving arrangement. Next slide, please. So I just want to give you a couple examples. Journals out there in the wild. This is a journal called Latin American policy. And their open access information reads that they offer authors that open access option to. But they charge a fee, an article publication charge, and APC. So this is an example of a hybrid journal. They are normally made earning their revenue via subscriptions, but there are also earning some revenue for selected open access articles. So this is the kind of thing that we're discouraging. Next slide. Same discipline, different journal. The Latin American research review is a fully open access journal, and they're open access policy sizes much they provide immediate open access to all of their content under a Creative Commons license. So they're allowing authors to retain copyright and making pretty liberal provisions for reuse of the material. Next slide. There are lots of there's lots of interesting, I guess, misinformation or confusion, I guess around some aspects of open access publishing. So I wanted to share some, some truths and some myths. And I probably should have done like a true and false quiz here, but I'm just going to tell you that it's true. Most open access publishing does not require transfer of copyright to the publisher for reasons that I've already explained. It is true that this is an access model and not appear a ViewModel. You will hear sometimes people say open access journals don't support peer review. Well, it's true that some open access journals don't support peer review. That is also true for some subscription journals. So don't rely on open access status as an indicator of peer review. If you're thinking about a journal, you wanted to take a look at their publication information to determine whether or not they offer peer review. It's also true that open access journals may charge a fee to authors, and that's a perfectly legitimate business model since they're not charging subscription fees and they presumably have some costs for doing what they do. It's us open up the potential for fraud. There are unscrupulous publishers out there that collect fees and post papers and claim to provide peer review, copy editing, fact-checking, whatever other kinds of services you might expect from a traditional publisher. And then they don't, they're deceitful about it. They they claim to do some things that they're not doing and they charge you for it. So you want to be on the lookout for these unscrupulous publishers. But there are plenty of good actors and the open access, well, we have more information for you on these topics. There's an open access library guide that includes, among other things, some starting points for finding open access journals in which to publish. We have a library guide on avoiding predatory publishers, these unscrupulous publishers. And the library has something called the Cornell open-access publication fund, where we can help you pay these article processing charges for qualifying journals. We do run out of money every year. It's popular service, so we've had to limit it to early career researchers, that is to say pre-tenure faculty, students and academic staff. And we do not support hybrid publishing arrangements. We'll pay for publication and fully open access journals for Cornell affiliated authors. Okay, next slide. There are other ways to share your papers. Certainly you can make use of the social networks that use for personal reasons. There are professional networks that provide some kind of similar functionality, but there, there are more professional environment. There are a pre-print services like archive and social archive in the Social Science Research Network, SSRN. And many, many, many more researchers often use these to post their papers ahead of publication for a variety of reasons. One, to, to stake their claim and an idea early on because scholarly publishing can move terribly slowly. And so it's nice to get it out there that, that you've done this work and these are your conclusions. People also post a pre-print servers because they're interested in keeping the, the progress in their discipline moving as quickly as possible. Again, because scholarly publishing can move slowly. And some people use pre-print services exclusively and bypass traditional publishing altogether, and that's certainly an option. And then again, we have platforms like e comments, institutional repositories, and discipline-based repositories. That can have the next slide. If you're thinking about using any of these services, you'll want to think about what it is they do and what you want them to do. If you're interested in keeping up on the literature in your discipline, you'll want to see if there's some way to do that. If you are interested in presenting a professional profile of yourself, I don't want to see if there's some way to do that. You might be interested in whether these platforms count, retain, and display. Statistics such as downloads and views of your work. You might be interested and professional networking and you might be interested in long-term preservation. And I'm sure there are other things that some of these platforms do that I haven't thought of. I go to the next slide. You will also want to think about what they're doing with your data, with their privacy policy is who's providing the service and what their motivation is. So if it's a commercial entity providing a free service, presumably they're trying to earn income some other way. And it could be by selling your data to another entity. And there's a great paper by Kathleen Fitzpatrick called academia and not edu. And a coat in that, that I like that kind of sums it up nicely, is that everything that's wrong with Facebook is wrong with academia.edu there one of these professional networking platforms that it's free to use, but they're selling your data. So use, use these things with care. And then I have to say, don't forget about copyright. If you haven't retain the copyright in your work, it may not be legal for you to post it to one of these sites, even though there's no technological impediment to doing that. All right, next slide. So one more example out in the wild, a, an article called national level, gender inequality and couple's income arrangements. Published in the Journal of Family and economic issues, which is a subscription journal. And I looked up their information and the Sherpa Romeo database, the author is allowed to post a draft to prevent repository or is our homepage with no delay, no embargo. So they've done that. They've posted the draft of this article to such Archive, which is a preprint server for the social sciences. So this is how they've found a way, even though they've published in a subscription journal to make their paper openly available. Next slide. 

Gail. Yeah, You had a question in chat and I just wanted to make sure I got it right. So the name of that article about academia.edu, it is called academia and not ideal. And the reason for that title is that at the time that they obtain that domain, it was legal to get a.edu domain even if you are not an educational organization, that's no longer legal. Okay? Or are these folks could have, in our example, they could have just published open access and posted once, but either one of these arrangements is really just fine in terms of trying to practice openness. Okay, next slide. So wrapping up with some best practices, first and foremost, understand and manage your rights as an author tried to keep as many of them as you can. One way to do that is publishing open access. Another way to do that is by just negotiating to retain some of those rights when you're not able to publish open access, definitely save your publishing agreement. See you know what you're allowed to do. And your last best draft, what's called the post-print, which is the drafts that results from your changes made in response to peer review, but before the publisher does any formatting or copy editing, quite often you're allowed to post that somewhere, perhaps after a delay. That'll be the often the best version you're allowed to post. When you do published with a traditional subscription-based journal, do try to find alternatives to complement that arrangement, but avoid hybrid open access. Avoid paying to open up your article in a subscription journal and evaluate any of these other services that you might use with some care. And I think that's it for me. Okay. Thank you. Go. So I'm going to conclude here by talking a little bit about research impact in the era of open scholarship. And as we open up, as it are, more and more options for publishing and putting your date out there and being more open. The question is, how does that, as a, as a researcher and a publisher, how does that affect my impact of my research? And I think the answer is, as always, it depends. And it really depends on how you define impact. And I saw before going into the way impact can and should be measured in an open environment. I think it's, i'll, I'll give a little bit of background about how traditionally in terms of the way, especially within the sciences, scholars publish and make their science available is through traditional publishing mental models. And the traditional way of measuring that, which is what we would call bibliometrics. So i'll, I'll talk a little bit about bibliometrics. I'm going to click go too deep into it because I think like anything else a little bit goes a long way and then talk a little bit about open scholarship and how does that, how does that the notion of opening up and publishing in an open access journal, for example, how does that affect the impact of your, of your research? And then I'll talk about some of the newer metrics. Scale said were there all these different ways of sharing now? And you know, are the, are the metrics kept catching up? And I think the answer is yes, slowly. Okay, so next slide, please. So this is a sort of a very colorful way of showing the difference between traditional, the traditional means of measuring research, impact. And then what? In an open environment, which isn't. Very many ways, is defined by increasing options for sharing your research. How does that differ? And so bibliometrics. And this is probably something all, everybody here has a somewhat of a sense of is like when you publish in a journal, the way the impact of you, your publications and the impact of you as a researcher and the impact of the journal you publish. And it's traditionally measured by citation counts. So if we think of databases like Web of Science and Scopus, they will, you know, when you publish your article, you will have listed in your literature review your bibliography or work cited, everything that you relied on. The databases will keep track of that. And it's essentially the measure. And the idea in, in the abstract makes a lot of sense is that, you know. The more citations you get from other scholars in your field or other people reading it within their own work. They read your work, they cite your work. The higher your citation counts, the greater the impact of your research. And I think to a certain degree that that's not false. But I think the problem is, is that it's tied to a traditional paywall environment where there really weren't any other options. If you wanted to get your scholarship out, you could talk to your colleagues at a conference perhaps and give a presentation. But, you know, really the primary and only means of getting the word out widely to the scientific community was through publishing in peer reviewed journals. And then you'd go to the reading room and your library and read them and then cite the work and go forward. But as we open up and there are a variety of means for publishing and a lot of the journals now become open access. The question is, do those citation counts still? Are they still a valid metric? And are there other ways of measuring that? So let's move on to the next slide. So the first, so there's this thing. So when you start to think of like, Oh, I'm going to publish in an open access journal by the fact that it's not paywall. And intuitively it makes sense that more people will read it and more people will cite it. And so this was the first thing in terms of making argument for publishing and open access. There has been a lot of discussion and claims about there being an open access citation advantage that using that traditional metric of the citation counts to your work. That if you make it freely available to everyone in the world, your citation counts will go up. Versus if you had published in a closed journal which is only available to subscribers. And the question is, is this true? So if we can move to the next slide, please. So here's an article. It's actually a systematic review that just came out in one of the leading open access journals. Plus 1 about is the open access citation and advantage real? And so there was a deep dive by some librarians. Some of them are at Minnesota. And anyway, they really looked at all the published literature about what the data said about the open access advantage. And the conclusion was, it depends. And it's, you know, it's what you really, what everybody wanted was this notion of like gets, of course, publishing and open access journal will increase your citation counts and thus your impact without going into too much detail because there's a lot of detail to systematic review. It's essentially, it really depends. It varies by field. There is some advantage for certain fields and there's no demonstrate double advantage in terms specifically of citation counts. So the latest we can determine in terms of like a systematic review says, it's not, it's not clear that you can say Absolutely, It varies and will probably change. Then the really interesting question becomes like, okay, So if there's not an obvious citation advantage while I, in terms of the impact of my research, should I be publishing in open access journals or making them available in a pre-print archives. Or if I have my poetry gives me the right, Make it is freely available as possible. I'm going all that work and I'm going outside of the traditions of paywall, peer reviewed journals. I know it's going to make any difference. And the real question is, what do you have to change your definition and expand your definition of impact. So if we can move on to the next slide, and this is where we bring in this notion of alternative metrics. And this is something that's been talked about for probably the last ten years or so. And there's more and more discussion. I remember going to a conference on this at the University of Toronto, maybe three or four years ago. And it's still, it's still a new thing. And essentially what it's taking is the idea of measuring impact of scholarship using not citation counts, but using alternatives. Which really tries to go to not the area where scholarship has the greatest impact is not just in that article, in that Elsevier published journal that your colleagues will read it. Now you have all these different options. You could be publishing in archive. You could be doing all these different things. The metrics are trying to catch up with that and so on this, if you're not familiar with it, on the left, is this that looks kind of like a five. It looks like an octopus, but with only five, I don't even know what you'd call them. That's plumb X. And each of those colors represents a different metric. And I'll go into this. We'll finish up with an example using the Flomax metric. And the other one is alt metrics, which is a donut. So it's the doughnut versus the plumb X has there. I'm not sure what it's called. But anyway, we'll go in and the colors represent. Various areas of impact that are not simply citation counts. So let's move on here. So I love this slide, even though it is highly detailed and I don't expect everyone to go into this. This again is from the foster group. And it really talks about, if you start over on the left with open science, it's a, it's a taxonomy and it's all the different parts of it. So the first or the second column is all those things under the umbrella of open science, open scholarship. One of them is open science and evaluation, just to give you a sense of it's its own thing. And then over on the right I have circled all these different areas, which includes like cementum metrics and WEBO metrics. And I'm not going to, if you want further information on that, feel free to shoot me an e-mail or just Google it. It's it's pretty geeky. I mean, it really is. But what I'm going to focus specifically here as an example of alt metrics. So what I'd like to do is kind of finish up my short and sweet exploration research metrics in an open environment by using a specific example of a, an article that was published fairly recently in New Political Economy. It's an open access journal. It was published in June of last year. The screenshot I've taken here is from Scopus, which is an Elsevier. They're pretty integrated at this point. I'm, and I'm not going to get sidetracked by talking about Elsevier and the research. But they're basically trying to buy up all the different areas where you evolve in terms of the research lifecycle and databases are, we pay a nice subscription for this? It's a great database. And this is a perfect example of an article and an open access journal that has, for a journal that's an article that's little over a year old. It has Two 112 citation. So this is the traditional bibliometrics that Scopus will offer you. And then if you want it to, on the right, you can see all the different publications since June of 2020 that have actually come out and cited as if you know anything about the way these things work. 200 citations in a little over a year is a really high impact in terms of bibliometrics article. But then what to say or if we can go to the next screen. So this is the same article, same database, but here we are looking at the plumb X metrics, which are alternative metrics. And each area within that color represents a different type of impact. So the citations are the orange area and that's traditional bibliometrics. But you can end the sort of the size of the circle represents the impact. But there are a lot of other interesting areas where Flomax is trying to measure the impact of the research. One of them is how many times these have been you within? And I'd like them to be extra coherency for something like the captures. Who's actually, who's downloaded into Mendel lay for example, mendeley is an open, quote unquote, open citation manager that many of you may be familiar with and use. It also happens to be owned by Elsevier and they nicely feed this back in here. Mandalay is a really good example of a different way of measuring the impact of your research. Because if someone is using a citation manager and downloads a citation to your work, that's a very different and more immediate measure of the impact of your research. That if somewhat actually goes through the trouble of publishing a journal article and then citing your work. So I'm not going to go into too much detail here, but it just gives you a nice example of the way alternative metrics are trying to show that the impact, especially in an open access environment, in an open access journal, Yes, this has a lot of citation counts and it's high impact in terms of bibliometrics, but in terms of other ways, they may actually be more valid and, and have a greater meaning to the impact of your work. Those are being captured and this is constantly evolving. The other interesting thing is diplomats started as an independent company and then 2017, Elsevier bought them. So they are again trying to pile. And I, I, it's kind of ironic that I'm using an example, alternative metrics and measuring the impact of your research in an open environment using a database like Scopus, which is close need, it's not an open access. And the plumb X metrics you can get access to. But it's kinda hard to do and it's much easier if your library has a subscription to Scopus, which we do. So we're very fortunate. At Cornell for that, but I think, you know, and I'm going to kind of wind it up there because I think, oh, thank you. It's diplomats. Amoeba. Yes, exactly. So you sort of get that sense of there. But I mean, I and this is going to change a lot because I think that the traditional knock on alternative metrics was, oh, it's just how many people are tweeting about your article. It's, it's the equivalent of your, your publication has the Lady Gaga fact, it's just because it's popular. Does it mean it's really high impact? No knocks against Lady Gaga. I loved Lady Gaga. But the idea is it's more than just how many people are tweeting your work. Because a high impact if you just counted tweets, worst scholarship in the world that said the world is flat and it got published in an article. A lot of people be like This is the worst scholarship ever. All Twitter knows there's a lot of people are tweeting about this research. So I think I just wanted to give a notion that given idea, I'll put it in your brains that the alternative metrics include more than just who's tweeting about your research. Not that, that's unimportant, but it's not just attention. It's actually usage which is beyond citation counts. So I think I'm going to turn it back over to Sarah for a wrap up. Thanks Dam. That was great. I am unmuted. Okay. So as we wrap up, I'd just like to close with a little bit of a request to everyone. So I think about research and scholarly publishing as kind of an ecosystem. So the saying from the ecological movement, think globally and act locally is still appropriate for our situation here, I think. And I know that you don't necessarily have control over a lot of things like thunder and publisher requirements, how tenure is decided, all those kind of things. But you do have control over what you do. And you can see the change and the broader ecosystem. So I asked you to think about and consider when you're planning your research and your publication practices. Just assume that the way others are doing it is the way it has to be. So think carefully about the choices you make as you move forward. Just keep thinking about how you can make decisions that are good, not just for you, but also for others around you and around the world. And even if you can make those little incremental changes, those nudges towards more open science, more open research, more open data, more open access publishing. These are just a few ways that you can contribute to a healthier ecosystem of knowledge, advance your career, and contribute to the public good. So I hope you think you keep those things in mind after this session. And I have one more. Maybe if I could get the thing to advance, I have one more poll for you guys. So after sitting here for an hour with us, are you inspired to make changes to the way you practice research? I can just say yes or no, but we'd love for you to throw a little bit more detail in there and you can texts these texts yes or no, and then text a longer response if you want to do that. We'd love to hear about what changes and why. And if it's too complicated to get into this poll, you can also throw it in the chat where everybody can see it there too. Good. I'm glad I'm not getting any angry nose. Been a wonderful audience today. Awesome. Well, if anybody wants to have follow-up conversations with any of us, I'm sure we would be happy to talk to you about any of the things we did or did not discuss about open scholarship. And thanks everybody for joining us. There. We had one question in the Q and a and I did type an answer that didn't know people are looking at that. So I just wanted to point it out because that was very good question on article publication charges and how that maybe results in a different kind of equity issue. And it certainly does in parts of the world where maybe those charges are on affordable. I think certainly the really high charges that nature and Elsevier charging every, are unaffordable to just about everybody. But many open access publishers do offer a waiver for income quote, authors and income qualifying countries. And actually one of the criteria to be considered to be listed in the directory of open access journals. And it's a criterion if you're applying to Cornell's open access publishing fund, the journal has to have a waiver policy in order for us to pay that fee. So it's a good question and it's still, it's still an issue. And you know, the people in the publishing world are also exploring other ways to sustain publish in that don't require charging authors that all the money's going to come from somewhere. So that's, that's a significant challenge. Thanks, Gail. Wonder if there are other questions or comments that people have. Yeah, if anybody wants to, you can put questions in the Q and a or in the chat. Or you can raise your hand and I'm happy to give you the ability to speak. And I just want to point out one more time now that we're at the end, there is the slides are available at this bitly slash open scholarship 2021 link, which I think has been put in the chat. Also. And I'll put it in the chat again. If nobody else has any questions, I guess we can end here. Thanks everybody for joining us. Yeah, thanks. That's a fascinating, an ongoing discussion and debate. 